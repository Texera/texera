// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               v5.28.0
// source: edu/uci/ics/amber/engine/architecture/sendsemantics/partitionings.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { ChannelIdentity } from "../../common/virtualidentity";

export const protobufPackage = "edu.uci.ics.amber.engine.architecture.sendsemantics";

export interface Partitioning {
  oneToOnePartitioning?: OneToOnePartitioning | undefined;
  roundRobinPartitioning?: RoundRobinPartitioning | undefined;
  hashBasedShufflePartitioning?: HashBasedShufflePartitioning | undefined;
  rangeBasedShufflePartitioning?: RangeBasedShufflePartitioning | undefined;
  broadcastPartitioning?: BroadcastPartitioning | undefined;
}

export interface OneToOnePartitioning {
  batchSize: number;
  channels: ChannelIdentity[];
}

export interface RoundRobinPartitioning {
  batchSize: number;
  channels: ChannelIdentity[];
}

export interface HashBasedShufflePartitioning {
  batchSize: number;
  channels: ChannelIdentity[];
  hashAttributeNames: string[];
}

export interface RangeBasedShufflePartitioning {
  batchSize: number;
  channels: ChannelIdentity[];
  rangeAttributeNames: string[];
  rangeMin: number;
  rangeMax: number;
}

export interface BroadcastPartitioning {
  batchSize: number;
  channels: ChannelIdentity[];
}

function createBasePartitioning(): Partitioning {
  return {
    oneToOnePartitioning: undefined,
    roundRobinPartitioning: undefined,
    hashBasedShufflePartitioning: undefined,
    rangeBasedShufflePartitioning: undefined,
    broadcastPartitioning: undefined,
  };
}

export const Partitioning: MessageFns<Partitioning> = {
  encode(message: Partitioning, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.oneToOnePartitioning !== undefined) {
      OneToOnePartitioning.encode(message.oneToOnePartitioning, writer.uint32(10).fork()).join();
    }
    if (message.roundRobinPartitioning !== undefined) {
      RoundRobinPartitioning.encode(message.roundRobinPartitioning, writer.uint32(18).fork()).join();
    }
    if (message.hashBasedShufflePartitioning !== undefined) {
      HashBasedShufflePartitioning.encode(message.hashBasedShufflePartitioning, writer.uint32(26).fork()).join();
    }
    if (message.rangeBasedShufflePartitioning !== undefined) {
      RangeBasedShufflePartitioning.encode(message.rangeBasedShufflePartitioning, writer.uint32(34).fork()).join();
    }
    if (message.broadcastPartitioning !== undefined) {
      BroadcastPartitioning.encode(message.broadcastPartitioning, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Partitioning {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePartitioning();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 10) {
            break;
          }

          message.oneToOnePartitioning = OneToOnePartitioning.decode(reader, reader.uint32());
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.roundRobinPartitioning = RoundRobinPartitioning.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.hashBasedShufflePartitioning = HashBasedShufflePartitioning.decode(reader, reader.uint32());
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.rangeBasedShufflePartitioning = RangeBasedShufflePartitioning.decode(reader, reader.uint32());
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.broadcastPartitioning = BroadcastPartitioning.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Partitioning {
    return {
      oneToOnePartitioning: isSet(object.oneToOnePartitioning)
        ? OneToOnePartitioning.fromJSON(object.oneToOnePartitioning)
        : undefined,
      roundRobinPartitioning: isSet(object.roundRobinPartitioning)
        ? RoundRobinPartitioning.fromJSON(object.roundRobinPartitioning)
        : undefined,
      hashBasedShufflePartitioning: isSet(object.hashBasedShufflePartitioning)
        ? HashBasedShufflePartitioning.fromJSON(object.hashBasedShufflePartitioning)
        : undefined,
      rangeBasedShufflePartitioning: isSet(object.rangeBasedShufflePartitioning)
        ? RangeBasedShufflePartitioning.fromJSON(object.rangeBasedShufflePartitioning)
        : undefined,
      broadcastPartitioning: isSet(object.broadcastPartitioning)
        ? BroadcastPartitioning.fromJSON(object.broadcastPartitioning)
        : undefined,
    };
  },

  toJSON(message: Partitioning): unknown {
    const obj: any = {};
    if (message.oneToOnePartitioning !== undefined) {
      obj.oneToOnePartitioning = OneToOnePartitioning.toJSON(message.oneToOnePartitioning);
    }
    if (message.roundRobinPartitioning !== undefined) {
      obj.roundRobinPartitioning = RoundRobinPartitioning.toJSON(message.roundRobinPartitioning);
    }
    if (message.hashBasedShufflePartitioning !== undefined) {
      obj.hashBasedShufflePartitioning = HashBasedShufflePartitioning.toJSON(message.hashBasedShufflePartitioning);
    }
    if (message.rangeBasedShufflePartitioning !== undefined) {
      obj.rangeBasedShufflePartitioning = RangeBasedShufflePartitioning.toJSON(message.rangeBasedShufflePartitioning);
    }
    if (message.broadcastPartitioning !== undefined) {
      obj.broadcastPartitioning = BroadcastPartitioning.toJSON(message.broadcastPartitioning);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Partitioning>, I>>(base?: I): Partitioning {
    return Partitioning.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Partitioning>, I>>(object: I): Partitioning {
    const message = createBasePartitioning();
    message.oneToOnePartitioning =
      object.oneToOnePartitioning !== undefined && object.oneToOnePartitioning !== null
        ? OneToOnePartitioning.fromPartial(object.oneToOnePartitioning)
        : undefined;
    message.roundRobinPartitioning =
      object.roundRobinPartitioning !== undefined && object.roundRobinPartitioning !== null
        ? RoundRobinPartitioning.fromPartial(object.roundRobinPartitioning)
        : undefined;
    message.hashBasedShufflePartitioning =
      object.hashBasedShufflePartitioning !== undefined && object.hashBasedShufflePartitioning !== null
        ? HashBasedShufflePartitioning.fromPartial(object.hashBasedShufflePartitioning)
        : undefined;
    message.rangeBasedShufflePartitioning =
      object.rangeBasedShufflePartitioning !== undefined && object.rangeBasedShufflePartitioning !== null
        ? RangeBasedShufflePartitioning.fromPartial(object.rangeBasedShufflePartitioning)
        : undefined;
    message.broadcastPartitioning =
      object.broadcastPartitioning !== undefined && object.broadcastPartitioning !== null
        ? BroadcastPartitioning.fromPartial(object.broadcastPartitioning)
        : undefined;
    return message;
  },
};

function createBaseOneToOnePartitioning(): OneToOnePartitioning {
  return { batchSize: 0, channels: [] };
}

export const OneToOnePartitioning: MessageFns<OneToOnePartitioning> = {
  encode(message: OneToOnePartitioning, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.batchSize !== 0) {
      writer.uint32(8).int32(message.batchSize);
    }
    for (const v of message.channels) {
      ChannelIdentity.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): OneToOnePartitioning {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseOneToOnePartitioning();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.batchSize = reader.int32();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.channels.push(ChannelIdentity.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): OneToOnePartitioning {
    return {
      batchSize: isSet(object.batchSize) ? globalThis.Number(object.batchSize) : 0,
      channels: globalThis.Array.isArray(object?.channels)
        ? object.channels.map((e: any) => ChannelIdentity.fromJSON(e))
        : [],
    };
  },

  toJSON(message: OneToOnePartitioning): unknown {
    const obj: any = {};
    if (message.batchSize !== 0) {
      obj.batchSize = Math.round(message.batchSize);
    }
    if (message.channels?.length) {
      obj.channels = message.channels.map(e => ChannelIdentity.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<OneToOnePartitioning>, I>>(base?: I): OneToOnePartitioning {
    return OneToOnePartitioning.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<OneToOnePartitioning>, I>>(object: I): OneToOnePartitioning {
    const message = createBaseOneToOnePartitioning();
    message.batchSize = object.batchSize ?? 0;
    message.channels = object.channels?.map(e => ChannelIdentity.fromPartial(e)) || [];
    return message;
  },
};

function createBaseRoundRobinPartitioning(): RoundRobinPartitioning {
  return { batchSize: 0, channels: [] };
}

export const RoundRobinPartitioning: MessageFns<RoundRobinPartitioning> = {
  encode(message: RoundRobinPartitioning, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.batchSize !== 0) {
      writer.uint32(8).int32(message.batchSize);
    }
    for (const v of message.channels) {
      ChannelIdentity.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RoundRobinPartitioning {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRoundRobinPartitioning();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.batchSize = reader.int32();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.channels.push(ChannelIdentity.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RoundRobinPartitioning {
    return {
      batchSize: isSet(object.batchSize) ? globalThis.Number(object.batchSize) : 0,
      channels: globalThis.Array.isArray(object?.channels)
        ? object.channels.map((e: any) => ChannelIdentity.fromJSON(e))
        : [],
    };
  },

  toJSON(message: RoundRobinPartitioning): unknown {
    const obj: any = {};
    if (message.batchSize !== 0) {
      obj.batchSize = Math.round(message.batchSize);
    }
    if (message.channels?.length) {
      obj.channels = message.channels.map(e => ChannelIdentity.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RoundRobinPartitioning>, I>>(base?: I): RoundRobinPartitioning {
    return RoundRobinPartitioning.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RoundRobinPartitioning>, I>>(object: I): RoundRobinPartitioning {
    const message = createBaseRoundRobinPartitioning();
    message.batchSize = object.batchSize ?? 0;
    message.channels = object.channels?.map(e => ChannelIdentity.fromPartial(e)) || [];
    return message;
  },
};

function createBaseHashBasedShufflePartitioning(): HashBasedShufflePartitioning {
  return { batchSize: 0, channels: [], hashAttributeNames: [] };
}

export const HashBasedShufflePartitioning: MessageFns<HashBasedShufflePartitioning> = {
  encode(message: HashBasedShufflePartitioning, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.batchSize !== 0) {
      writer.uint32(8).int32(message.batchSize);
    }
    for (const v of message.channels) {
      ChannelIdentity.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.hashAttributeNames) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HashBasedShufflePartitioning {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHashBasedShufflePartitioning();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.batchSize = reader.int32();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.channels.push(ChannelIdentity.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.hashAttributeNames.push(reader.string());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HashBasedShufflePartitioning {
    return {
      batchSize: isSet(object.batchSize) ? globalThis.Number(object.batchSize) : 0,
      channels: globalThis.Array.isArray(object?.channels)
        ? object.channels.map((e: any) => ChannelIdentity.fromJSON(e))
        : [],
      hashAttributeNames: globalThis.Array.isArray(object?.hashAttributeNames)
        ? object.hashAttributeNames.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: HashBasedShufflePartitioning): unknown {
    const obj: any = {};
    if (message.batchSize !== 0) {
      obj.batchSize = Math.round(message.batchSize);
    }
    if (message.channels?.length) {
      obj.channels = message.channels.map(e => ChannelIdentity.toJSON(e));
    }
    if (message.hashAttributeNames?.length) {
      obj.hashAttributeNames = message.hashAttributeNames;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<HashBasedShufflePartitioning>, I>>(base?: I): HashBasedShufflePartitioning {
    return HashBasedShufflePartitioning.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<HashBasedShufflePartitioning>, I>>(object: I): HashBasedShufflePartitioning {
    const message = createBaseHashBasedShufflePartitioning();
    message.batchSize = object.batchSize ?? 0;
    message.channels = object.channels?.map(e => ChannelIdentity.fromPartial(e)) || [];
    message.hashAttributeNames = object.hashAttributeNames?.map(e => e) || [];
    return message;
  },
};

function createBaseRangeBasedShufflePartitioning(): RangeBasedShufflePartitioning {
  return { batchSize: 0, channels: [], rangeAttributeNames: [], rangeMin: 0, rangeMax: 0 };
}

export const RangeBasedShufflePartitioning: MessageFns<RangeBasedShufflePartitioning> = {
  encode(message: RangeBasedShufflePartitioning, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.batchSize !== 0) {
      writer.uint32(8).int32(message.batchSize);
    }
    for (const v of message.channels) {
      ChannelIdentity.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.rangeAttributeNames) {
      writer.uint32(26).string(v!);
    }
    if (message.rangeMin !== 0) {
      writer.uint32(32).int64(message.rangeMin);
    }
    if (message.rangeMax !== 0) {
      writer.uint32(40).int64(message.rangeMax);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RangeBasedShufflePartitioning {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRangeBasedShufflePartitioning();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.batchSize = reader.int32();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.channels.push(ChannelIdentity.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.rangeAttributeNames.push(reader.string());
          continue;
        case 4:
          if (tag !== 32) {
            break;
          }

          message.rangeMin = longToNumber(reader.int64());
          continue;
        case 5:
          if (tag !== 40) {
            break;
          }

          message.rangeMax = longToNumber(reader.int64());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RangeBasedShufflePartitioning {
    return {
      batchSize: isSet(object.batchSize) ? globalThis.Number(object.batchSize) : 0,
      channels: globalThis.Array.isArray(object?.channels)
        ? object.channels.map((e: any) => ChannelIdentity.fromJSON(e))
        : [],
      rangeAttributeNames: globalThis.Array.isArray(object?.rangeAttributeNames)
        ? object.rangeAttributeNames.map((e: any) => globalThis.String(e))
        : [],
      rangeMin: isSet(object.rangeMin) ? globalThis.Number(object.rangeMin) : 0,
      rangeMax: isSet(object.rangeMax) ? globalThis.Number(object.rangeMax) : 0,
    };
  },

  toJSON(message: RangeBasedShufflePartitioning): unknown {
    const obj: any = {};
    if (message.batchSize !== 0) {
      obj.batchSize = Math.round(message.batchSize);
    }
    if (message.channels?.length) {
      obj.channels = message.channels.map(e => ChannelIdentity.toJSON(e));
    }
    if (message.rangeAttributeNames?.length) {
      obj.rangeAttributeNames = message.rangeAttributeNames;
    }
    if (message.rangeMin !== 0) {
      obj.rangeMin = Math.round(message.rangeMin);
    }
    if (message.rangeMax !== 0) {
      obj.rangeMax = Math.round(message.rangeMax);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RangeBasedShufflePartitioning>, I>>(base?: I): RangeBasedShufflePartitioning {
    return RangeBasedShufflePartitioning.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RangeBasedShufflePartitioning>, I>>(
    object: I
  ): RangeBasedShufflePartitioning {
    const message = createBaseRangeBasedShufflePartitioning();
    message.batchSize = object.batchSize ?? 0;
    message.channels = object.channels?.map(e => ChannelIdentity.fromPartial(e)) || [];
    message.rangeAttributeNames = object.rangeAttributeNames?.map(e => e) || [];
    message.rangeMin = object.rangeMin ?? 0;
    message.rangeMax = object.rangeMax ?? 0;
    return message;
  },
};

function createBaseBroadcastPartitioning(): BroadcastPartitioning {
  return { batchSize: 0, channels: [] };
}

export const BroadcastPartitioning: MessageFns<BroadcastPartitioning> = {
  encode(message: BroadcastPartitioning, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.batchSize !== 0) {
      writer.uint32(8).int32(message.batchSize);
    }
    for (const v of message.channels) {
      ChannelIdentity.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BroadcastPartitioning {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBroadcastPartitioning();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.batchSize = reader.int32();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.channels.push(ChannelIdentity.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BroadcastPartitioning {
    return {
      batchSize: isSet(object.batchSize) ? globalThis.Number(object.batchSize) : 0,
      channels: globalThis.Array.isArray(object?.channels)
        ? object.channels.map((e: any) => ChannelIdentity.fromJSON(e))
        : [],
    };
  },

  toJSON(message: BroadcastPartitioning): unknown {
    const obj: any = {};
    if (message.batchSize !== 0) {
      obj.batchSize = Math.round(message.batchSize);
    }
    if (message.channels?.length) {
      obj.channels = message.channels.map(e => ChannelIdentity.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<BroadcastPartitioning>, I>>(base?: I): BroadcastPartitioning {
    return BroadcastPartitioning.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<BroadcastPartitioning>, I>>(object: I): BroadcastPartitioning {
    const message = createBaseBroadcastPartitioning();
    message.batchSize = object.batchSize ?? 0;
    message.channels = object.channels?.map(e => ChannelIdentity.fromPartial(e)) || [];
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin
  ? T
  : T extends globalThis.Array<infer U>
    ? globalThis.Array<DeepPartial<U>>
    : T extends ReadonlyArray<infer U>
      ? ReadonlyArray<DeepPartial<U>>
      : T extends {}
        ? { [K in keyof T]?: DeepPartial<T[K]> }
        : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin
  ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P>>]: never };

function longToNumber(int64: { toString(): string }): number {
  const num = globalThis.Number(int64.toString());
  if (num > globalThis.Number.MAX_SAFE_INTEGER) {
    throw new globalThis.Error("Value is larger than Number.MAX_SAFE_INTEGER");
  }
  if (num < globalThis.Number.MIN_SAFE_INTEGER) {
    throw new globalThis.Error("Value is smaller than Number.MIN_SAFE_INTEGER");
  }
  return num;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create<I extends Exact<DeepPartial<T>, I>>(base?: I): T;
  fromPartial<I extends Exact<DeepPartial<T>, I>>(object: I): T;
}
