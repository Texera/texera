package edu.uci.ics.texera.workflow.operators.machineLearning.Scorer

import com.fasterxml.jackson.annotation.{JsonProperty, JsonPropertyDescription}
import com.kjetland.jackson.jsonSchema.annotations.{JsonSchemaInject, JsonSchemaString, JsonSchemaTitle}
import edu.uci.ics.amber.engine.common.workflow.{InputPort, OutputPort, PortIdentity}
import edu.uci.ics.texera.workflow.common.metadata.annotations.{AutofillAttributeName, AutofillAttributeNameOnPort1, HideAnnotation}
import edu.uci.ics.texera.workflow.common.metadata.{OperatorGroupConstants, OperatorInfo}
import edu.uci.ics.texera.workflow.common.operators.PythonOperatorDescriptor
import edu.uci.ics.texera.workflow.common.tuple.schema.{Attribute, AttributeType, Schema}

class ScorerOpDesc extends PythonOperatorDescriptor {
  @JsonProperty(required = false, defaultValue = "false")
  @JsonSchemaTitle("Regression")
  @JsonPropertyDescription(
    "Choose to solve a regression task"
  )
  var isRegression: Boolean = false

  @JsonProperty(required = true)
  @JsonSchemaTitle("Actual Value")
  @JsonPropertyDescription("Specify the label column")
  @AutofillAttributeName
  var actualValueColumn: String = ""

  @JsonProperty(required = true)
  @JsonSchemaTitle("Predicted Value")
  @JsonPropertyDescription("Specify the attribute generated by the model")
  @AutofillAttributeNameOnPort1
  var predictValueColumn: String = ""

  @JsonProperty(required = false, value = "classificationFlag")
  @JsonSchemaTitle("Scorer Functions")
  @JsonPropertyDescription("Select classification tasks metrics")
  @JsonSchemaInject(
    strings = Array(
      new JsonSchemaString(path = HideAnnotation.hideTarget, value = "isRegression"),
      new JsonSchemaString(path = HideAnnotation.hideType, value = HideAnnotation.Type.equals),
      new JsonSchemaString(path = HideAnnotation.hideExpectedValue, value = "true")
    )
  )
  var classificationMetrics: List[classificationMetricsFnc] = List()

  @JsonProperty(required = false, value = "regressionFlag")
  @JsonSchemaTitle("Scorer Functions")
  @JsonPropertyDescription("Select regression tasks metrics")
  @JsonSchemaInject(
    strings = Array(
      new JsonSchemaString(path = HideAnnotation.hideTarget, value = "isRegression"),
      new JsonSchemaString(path = HideAnnotation.hideType, value = HideAnnotation.Type.equals),
      new JsonSchemaString(path = HideAnnotation.hideExpectedValue, value = "false")
    )
  )
  var regressionMetrics: List[regressionMetricsFnc] = List()

  override def operatorInfo: OperatorInfo =
    OperatorInfo(
      "Scorer",
      "Scorer for machine learning models",
      OperatorGroupConstants.MODEL_PERFORMANCE_GROUP,
      inputPorts = List(
        InputPort(
          PortIdentity(0),
          displayName = "groundTruth",
          allowMultiLinks = true
        ),
        InputPort(
          PortIdentity(1),
          displayName = "predictionData",
          allowMultiLinks = true,
          dependencies = List(PortIdentity(0))
        )
      ),
      outputPorts = List(OutputPort())
    )
  override def getOutputSchema(schemas: Array[Schema]): Schema = {
    val outputSchemaBuilder = Schema.builder()
    outputSchemaBuilder.add(new Attribute("Label", AttributeType.STRING))

    if (isRegression) {
      regressionMetrics.foreach(metric => {
        outputSchemaBuilder.add(new Attribute(metric.getName(), AttributeType.DOUBLE))
      })
    }
    else {
      classificationMetrics.foreach(metric => {
        outputSchemaBuilder.add(new Attribute(metric.getName(), AttributeType.DOUBLE))
      })
    }

    outputSchemaBuilder.build()
  }

  private def getClassificationScorerName(scorer: classificationMetricsFnc): String = {
    // Directly return the name of the scorer using the getName() method
    scorer.getName()
  }
  private def getRegressionScorerName(scorer: regressionMetricsFnc): String = {
    // Directly return the name of the scorer using the getName() method
    scorer.getName()
  }

  private def getEachScorerName(scorer: Any): String = scorer match {
    case s: classificationMetricsFnc => getClassificationScorerName(s)
    case s: regressionMetricsFnc => getRegressionScorerName(s)
    case _ => throw new IllegalArgumentException("Unknown scorer type")
  }

  private def getSelectedScorers(): String = {
    // Return a string of scorers using the getEachScorerName() method
    var scorers: List[_] = List()
    if (isRegression) scorers = regressionMetrics
    else scorers = classificationMetrics

    scorers.map(scorer => getEachScorerName(scorer)).mkString("'", "','", "'")
  }

  override def generatePythonCode(): String = {
    var is_regression = "False"
    if (isRegression) is_regression = "True"
    val finalcode =
      s"""
         |from pytexera import *
         |import pandas as pd
         |import numpy as np
         |from sklearn.metrics import accuracy_score
         |from sklearn.metrics import precision_score
         |from sklearn.metrics import confusion_matrix
         |from sklearn.metrics import recall_score
         |from sklearn.metrics import f1_score
         |from sklearn.metrics import mean_squared_error
         |from sklearn.metrics import root_mean_squared_error
         |from sklearn.metrics import mean_absolute_error
         |from sklearn.metrics import r2_score
         |import json
         |
         |
         |def classification_scorers(y_true, y_pred, scorer_list, labels):
         |  result = dict()
         |
         |  for scorer in scorer_list:
         |    result[scorer] = [ None ] * len(labels)
         |
         |  for scorer in scorer_list:
         |    prediction = None
         |    if scorer == 'Accuracy':
         |      result['Accuracy'][len(labels) - 1] = accuracy_score(y_true, y_pred)
         |
         |    elif scorer == 'Precision Score':
         |      for i in range(len(labels)):
         |        if labels[i] != 'Overall':
         |          prediction = precision_score(y_true, y_pred, average = None, labels = [labels[i]])
         |          result['Precision Score'][i] = prediction[0]
         |        else:
         |          result['Precision Score'][i] = precision_score(y_true, y_pred, average = 'macro')
         |
         |    elif scorer == 'Recall Score':
         |      for i in range(len(labels)):
         |        if labels[i] != 'Overall':
         |          prediction = recall_score(y_true, y_pred, average = None, labels = [labels[i]])
         |          result['Recall Score'][i] = prediction[0]
         |        else:
         |          result['Recall Score'][i] = recall_score(y_true, y_pred, average = 'macro')
         |
         |    elif scorer == 'F1 Score':
         |      for i in range(len(labels)):
         |        if labels[i] != 'Overall':
         |          prediction = f1_score(y_true, y_pred, average = None, labels = [labels[i]])
         |          result['F1 Score'][i] = prediction[0]
         |        else:
         |          result['F1 Score'][i] = f1_score(y_true, y_pred, average = 'macro')
         |
         |  for i in range(len(labels)):
         |    if type(labels[i]) != str:
         |      labels[i] = ('class_' + str(labels[i]))
         |
         |  result['Label'] = labels
         |
         |  result_df = pd.DataFrame(result)
         |
         |  return result_df
         |
         |
         |def regression_scorers(y_true, y_pred, scorer_list):
         |  result = dict()
         |  for scorer in scorer_list:
         |    if scorer == 'MSE':
         |      result['MSE'] = mean_squared_error(y_true, y_pred)
         |
         |    elif scorer == 'RMSE':
         |      result['RMSE'] = root_mean_squared_error(y_true, y_pred)
         |
         |    elif scorer == "MAE":
         |      result['MAE'] = mean_absolute_error(y_true, y_pred)
         |
         |    elif scorer == 'R2':
         |      result['R2'] = r2_score(y_true, y_pred)
         |
         |  # convert list/dict to dataframe
         |  label = ['Overall']
         |  label_df = pd.DataFrame(label, columns=['Label'])
         |  result_df = pd.DataFrame(result, index=[0])
         |  result_df = pd.concat([label_df, result_df], axis=1)
         |
         |  return result_df
         |
         |class ProcessTableOperator(UDFTableOperator):
         |
         |    @overrides
         |    def process_table(self, table: Table, port: int) -> Iterator[Optional[TableLike]]:
         |      global test_data
         |      global predict_data
         |
         |      if port == 0:
         |        test_data = table
         |
         |      if port == 1:
         |        predict_data = table
         |        result = dict()
         |
         |        y_true = test_data['$actualValueColumn']
         |        y_pred = predict_data['$predictValueColumn']
         |
         |        scorer_list = [${getSelectedScorers()}]
         |
         |        if $is_regression:
         |          result = regression_scorers(y_true, y_pred, scorer_list)
         |        else:
         |          labels = list(set(y_true))
         |          labels.append('Overall')
         |          y_true_str = y_true.astype(str)
         |          result = classification_scorers(y_true_str, y_pred, scorer_list, labels)
         |
         |
         |        yield result
         |
         |
         |""".stripMargin
    finalcode
  }

}