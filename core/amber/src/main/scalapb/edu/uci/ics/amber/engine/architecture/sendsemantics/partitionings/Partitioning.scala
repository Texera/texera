// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!
//
// Protofile syntax: PROTO3

package edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings

sealed trait Partitioning extends scalapb.GeneratedSealedOneof {
  type MessageType = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage
  final def isEmpty = this.isInstanceOf[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.Empty.type]
  final def isDefined = !isEmpty
  final def asMessage: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.PartitioningTypeMapper.toBase(this)
  final def asNonEmpty: Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.NonEmpty] = if (isEmpty) None else Some(this.asInstanceOf[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.NonEmpty])
}

object Partitioning {
  case object Empty extends edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning
  
  sealed trait NonEmpty extends edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning
  def defaultInstance: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning = Empty
  
  implicit val PartitioningTypeMapper: _root_.scalapb.TypeMapper[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning] = new _root_.scalapb.TypeMapper[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning] {
    override def toCustom(__base: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage): edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning = __base.sealedValue match {
      case __v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.OneToOnePartitioning => __v.value
      case __v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RoundRobinPartitioning => __v.value
      case __v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.HashBasedShufflePartitioning => __v.value
      case __v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RangeBasedShufflePartitioning => __v.value
      case __v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.BroadcastPartitioning => __v.value
      case edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.Empty => Empty
    }
    override def toBase(__custom: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning): edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage(__custom match {
      case __v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning => edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.OneToOnePartitioning(__v)
      case __v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning => edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RoundRobinPartitioning(__v)
      case __v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning => edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.HashBasedShufflePartitioning(__v)
      case __v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning => edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RangeBasedShufflePartitioning(__v)
      case __v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning => edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.BroadcastPartitioning(__v)
      case Empty => edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.Empty
    })
  }
}
@SerialVersionUID(0L)
final case class PartitioningMessage(
    sealedValue: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[PartitioningMessage] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      if (sealedValue.oneToOnePartitioning.isDefined) {
        val __value = sealedValue.oneToOnePartitioning.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      if (sealedValue.roundRobinPartitioning.isDefined) {
        val __value = sealedValue.roundRobinPartitioning.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      if (sealedValue.hashBasedShufflePartitioning.isDefined) {
        val __value = sealedValue.hashBasedShufflePartitioning.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      if (sealedValue.rangeBasedShufflePartitioning.isDefined) {
        val __value = sealedValue.rangeBasedShufflePartitioning.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      if (sealedValue.broadcastPartitioning.isDefined) {
        val __value = sealedValue.broadcastPartitioning.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      sealedValue.oneToOnePartitioning.foreach { __v =>
        val __m = __v
        _output__.writeTag(1, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      sealedValue.roundRobinPartitioning.foreach { __v =>
        val __m = __v
        _output__.writeTag(2, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      sealedValue.hashBasedShufflePartitioning.foreach { __v =>
        val __m = __v
        _output__.writeTag(3, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      sealedValue.rangeBasedShufflePartitioning.foreach { __v =>
        val __m = __v
        _output__.writeTag(4, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      sealedValue.broadcastPartitioning.foreach { __v =>
        val __m = __v
        _output__.writeTag(5, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
    }
    def getOneToOnePartitioning: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning = sealedValue.oneToOnePartitioning.getOrElse(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning.defaultInstance)
    def withOneToOnePartitioning(__v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning): PartitioningMessage = copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.OneToOnePartitioning(__v))
    def getRoundRobinPartitioning: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning = sealedValue.roundRobinPartitioning.getOrElse(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning.defaultInstance)
    def withRoundRobinPartitioning(__v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning): PartitioningMessage = copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RoundRobinPartitioning(__v))
    def getHashBasedShufflePartitioning: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning = sealedValue.hashBasedShufflePartitioning.getOrElse(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning.defaultInstance)
    def withHashBasedShufflePartitioning(__v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning): PartitioningMessage = copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.HashBasedShufflePartitioning(__v))
    def getRangeBasedShufflePartitioning: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning = sealedValue.rangeBasedShufflePartitioning.getOrElse(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning.defaultInstance)
    def withRangeBasedShufflePartitioning(__v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning): PartitioningMessage = copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RangeBasedShufflePartitioning(__v))
    def getBroadcastPartitioning: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning = sealedValue.broadcastPartitioning.getOrElse(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning.defaultInstance)
    def withBroadcastPartitioning(__v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning): PartitioningMessage = copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.BroadcastPartitioning(__v))
    def clearSealedValue: PartitioningMessage = copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.Empty)
    def withSealedValue(__v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue): PartitioningMessage = copy(sealedValue = __v)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => sealedValue.oneToOnePartitioning.orNull
        case 2 => sealedValue.roundRobinPartitioning.orNull
        case 3 => sealedValue.hashBasedShufflePartitioning.orNull
        case 4 => sealedValue.rangeBasedShufflePartitioning.orNull
        case 5 => sealedValue.broadcastPartitioning.orNull
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => sealedValue.oneToOnePartitioning.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 2 => sealedValue.roundRobinPartitioning.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 3 => sealedValue.hashBasedShufflePartitioning.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 4 => sealedValue.rangeBasedShufflePartitioning.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 5 => sealedValue.broadcastPartitioning.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToSingleLineUnicodeString(this)
    def companion: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.type = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage
    def toPartitioning: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.PartitioningTypeMapper.toCustom(this)
    // @@protoc_insertion_point(GeneratedMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.Partitioning])
}

object PartitioningMessage extends scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage = {
    var __sealedValue: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.Empty
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 10 =>
          __sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.OneToOnePartitioning(__sealedValue.oneToOnePartitioning.fold(_root_.scalapb.LiteParser.readMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case 18 =>
          __sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RoundRobinPartitioning(__sealedValue.roundRobinPartitioning.fold(_root_.scalapb.LiteParser.readMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case 26 =>
          __sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.HashBasedShufflePartitioning(__sealedValue.hashBasedShufflePartitioning.fold(_root_.scalapb.LiteParser.readMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case 34 =>
          __sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RangeBasedShufflePartitioning(__sealedValue.rangeBasedShufflePartitioning.fold(_root_.scalapb.LiteParser.readMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case 42 =>
          __sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.BroadcastPartitioning(__sealedValue.broadcastPartitioning.fold(_root_.scalapb.LiteParser.readMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case tag => _input__.skipField(tag)
      }
    }
    edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage(
        sealedValue = __sealedValue
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage(
        sealedValue = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).flatMap(_.as[_root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning]]).map(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.OneToOnePartitioning(_))
            .orElse[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue](__fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).flatMap(_.as[_root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning]]).map(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RoundRobinPartitioning(_)))
            .orElse[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue](__fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).flatMap(_.as[_root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning]]).map(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.HashBasedShufflePartitioning(_)))
            .orElse[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue](__fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).flatMap(_.as[_root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning]]).map(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RangeBasedShufflePartitioning(_)))
            .orElse[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue](__fieldsMap.get(scalaDescriptor.findFieldByNumber(5).get).flatMap(_.as[_root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning]]).map(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.BroadcastPartitioning(_)))
            .getOrElse(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.Empty)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = PartitioningsProto.javaDescriptor.getMessageTypes().get(0)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = PartitioningsProto.scalaDescriptor.messages(0)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 1 => __out = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning
      case 2 => __out = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning
      case 3 => __out = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning
      case 4 => __out = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning
      case 5 => __out = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage(
    sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.Empty
  )
  sealed trait SealedValue extends _root_.scalapb.GeneratedOneof {
    def isEmpty: _root_.scala.Boolean = false
    def isDefined: _root_.scala.Boolean = true
    def isOneToOnePartitioning: _root_.scala.Boolean = false
    def isRoundRobinPartitioning: _root_.scala.Boolean = false
    def isHashBasedShufflePartitioning: _root_.scala.Boolean = false
    def isRangeBasedShufflePartitioning: _root_.scala.Boolean = false
    def isBroadcastPartitioning: _root_.scala.Boolean = false
    def oneToOnePartitioning: _root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning] = _root_.scala.None
    def roundRobinPartitioning: _root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning] = _root_.scala.None
    def hashBasedShufflePartitioning: _root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning] = _root_.scala.None
    def rangeBasedShufflePartitioning: _root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning] = _root_.scala.None
    def broadcastPartitioning: _root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning] = _root_.scala.None
  }
  object SealedValue {
    @SerialVersionUID(0L)
    case object Empty extends edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue {
      type ValueType = _root_.scala.Nothing
      override def isEmpty: _root_.scala.Boolean = true
      override def isDefined: _root_.scala.Boolean = false
      override def number: _root_.scala.Int = 0
      override def value: _root_.scala.Nothing = throw new java.util.NoSuchElementException("Empty.value")
    }
  
    @SerialVersionUID(0L)
    final case class OneToOnePartitioning(value: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning) extends edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue {
      type ValueType = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning
      override def isOneToOnePartitioning: _root_.scala.Boolean = true
      override def oneToOnePartitioning: _root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning] = Some(value)
      override def number: _root_.scala.Int = 1
    }
    @SerialVersionUID(0L)
    final case class RoundRobinPartitioning(value: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning) extends edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue {
      type ValueType = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning
      override def isRoundRobinPartitioning: _root_.scala.Boolean = true
      override def roundRobinPartitioning: _root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning] = Some(value)
      override def number: _root_.scala.Int = 2
    }
    @SerialVersionUID(0L)
    final case class HashBasedShufflePartitioning(value: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning) extends edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue {
      type ValueType = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning
      override def isHashBasedShufflePartitioning: _root_.scala.Boolean = true
      override def hashBasedShufflePartitioning: _root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning] = Some(value)
      override def number: _root_.scala.Int = 3
    }
    @SerialVersionUID(0L)
    final case class RangeBasedShufflePartitioning(value: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning) extends edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue {
      type ValueType = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning
      override def isRangeBasedShufflePartitioning: _root_.scala.Boolean = true
      override def rangeBasedShufflePartitioning: _root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning] = Some(value)
      override def number: _root_.scala.Int = 4
    }
    @SerialVersionUID(0L)
    final case class BroadcastPartitioning(value: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning) extends edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue {
      type ValueType = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning
      override def isBroadcastPartitioning: _root_.scala.Boolean = true
      override def broadcastPartitioning: _root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning] = Some(value)
      override def number: _root_.scala.Int = 5
    }
  }
  implicit class PartitioningMessageLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage](_l) {
    def oneToOnePartitioning: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning] = field(_.getOneToOnePartitioning)((c_, f_) => c_.copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.OneToOnePartitioning(f_)))
    def roundRobinPartitioning: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning] = field(_.getRoundRobinPartitioning)((c_, f_) => c_.copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RoundRobinPartitioning(f_)))
    def hashBasedShufflePartitioning: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning] = field(_.getHashBasedShufflePartitioning)((c_, f_) => c_.copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.HashBasedShufflePartitioning(f_)))
    def rangeBasedShufflePartitioning: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning] = field(_.getRangeBasedShufflePartitioning)((c_, f_) => c_.copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RangeBasedShufflePartitioning(f_)))
    def broadcastPartitioning: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning] = field(_.getBroadcastPartitioning)((c_, f_) => c_.copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.BroadcastPartitioning(f_)))
    def sealedValue: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue] = field(_.sealedValue)((c_, f_) => c_.copy(sealedValue = f_))
  }
  final val ONETOONEPARTITIONING_FIELD_NUMBER = 1
  final val ROUNDROBINPARTITIONING_FIELD_NUMBER = 2
  final val HASHBASEDSHUFFLEPARTITIONING_FIELD_NUMBER = 3
  final val RANGEBASEDSHUFFLEPARTITIONING_FIELD_NUMBER = 4
  final val BROADCASTPARTITIONING_FIELD_NUMBER = 5
  def of(
    sealedValue: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue
  ): _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage = _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage(
    sealedValue
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.Partitioning])
}

@SerialVersionUID(0L)
final case class OneToOnePartitioning(
    batchSize: _root_.scala.Int,
    channels: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]
    ) extends scalapb.GeneratedMessage with edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.NonEmpty with scalapb.lenses.Updatable[OneToOnePartitioning] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = batchSize
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(1, __value)
        }
      };
      channels.foreach { __item =>
        val __value = __item
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = batchSize
        if (__v != 0) {
          _output__.writeInt32(1, __v)
        }
      };
      channels.foreach { __v =>
        val __m = __v
        _output__.writeTag(2, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
    }
    def withBatchSize(__v: _root_.scala.Int): OneToOnePartitioning = copy(batchSize = __v)
    def clearChannels = copy(channels = _root_.scala.Seq.empty)
    def addChannels(__vs: edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity *): OneToOnePartitioning = addAllChannels(__vs)
    def addAllChannels(__vs: Iterable[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]): OneToOnePartitioning = copy(channels = channels ++ __vs)
    def withChannels(__v: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]): OneToOnePartitioning = copy(channels = __v)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = batchSize
          if (__t != 0) __t else null
        }
        case 2 => channels
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PInt(batchSize)
        case 2 => _root_.scalapb.descriptors.PRepeated(channels.iterator.map(_.toPMessage).toVector)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToSingleLineUnicodeString(this)
    def companion: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning.type = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning
    // @@protoc_insertion_point(GeneratedMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.OneToOnePartitioning])
}

object OneToOnePartitioning extends scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning = {
    var __batchSize: _root_.scala.Int = 0
    val __channels: _root_.scala.collection.immutable.VectorBuilder[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity] = new _root_.scala.collection.immutable.VectorBuilder[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 8 =>
          __batchSize = _input__.readInt32()
        case 18 =>
          __channels += _root_.scalapb.LiteParser.readMessage[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity](_input__)
        case tag => _input__.skipField(tag)
      }
    }
    edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning(
        batchSize = __batchSize,
        channels = __channels.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning(
        batchSize = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        channels = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]]).getOrElse(_root_.scala.Seq.empty)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = PartitioningsProto.javaDescriptor.getMessageTypes().get(1)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = PartitioningsProto.scalaDescriptor.messages(1)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 2 => __out = edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning(
    batchSize = 0,
    channels = _root_.scala.Seq.empty
  )
  implicit class OneToOnePartitioningLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning](_l) {
    def batchSize: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.batchSize)((c_, f_) => c_.copy(batchSize = f_))
    def channels: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]] = field(_.channels)((c_, f_) => c_.copy(channels = f_))
  }
  final val BATCHSIZE_FIELD_NUMBER = 1
  final val CHANNELS_FIELD_NUMBER = 2
  def of(
    batchSize: _root_.scala.Int,
    channels: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]
  ): _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning = _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning(
    batchSize,
    channels
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.OneToOnePartitioning])
}

@SerialVersionUID(0L)
final case class RoundRobinPartitioning(
    batchSize: _root_.scala.Int,
    channels: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]
    ) extends scalapb.GeneratedMessage with edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.NonEmpty with scalapb.lenses.Updatable[RoundRobinPartitioning] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = batchSize
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(1, __value)
        }
      };
      channels.foreach { __item =>
        val __value = __item
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = batchSize
        if (__v != 0) {
          _output__.writeInt32(1, __v)
        }
      };
      channels.foreach { __v =>
        val __m = __v
        _output__.writeTag(2, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
    }
    def withBatchSize(__v: _root_.scala.Int): RoundRobinPartitioning = copy(batchSize = __v)
    def clearChannels = copy(channels = _root_.scala.Seq.empty)
    def addChannels(__vs: edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity *): RoundRobinPartitioning = addAllChannels(__vs)
    def addAllChannels(__vs: Iterable[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]): RoundRobinPartitioning = copy(channels = channels ++ __vs)
    def withChannels(__v: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]): RoundRobinPartitioning = copy(channels = __v)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = batchSize
          if (__t != 0) __t else null
        }
        case 2 => channels
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PInt(batchSize)
        case 2 => _root_.scalapb.descriptors.PRepeated(channels.iterator.map(_.toPMessage).toVector)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToSingleLineUnicodeString(this)
    def companion: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning.type = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning
    // @@protoc_insertion_point(GeneratedMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.RoundRobinPartitioning])
}

object RoundRobinPartitioning extends scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning = {
    var __batchSize: _root_.scala.Int = 0
    val __channels: _root_.scala.collection.immutable.VectorBuilder[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity] = new _root_.scala.collection.immutable.VectorBuilder[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 8 =>
          __batchSize = _input__.readInt32()
        case 18 =>
          __channels += _root_.scalapb.LiteParser.readMessage[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity](_input__)
        case tag => _input__.skipField(tag)
      }
    }
    edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning(
        batchSize = __batchSize,
        channels = __channels.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning(
        batchSize = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        channels = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]]).getOrElse(_root_.scala.Seq.empty)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = PartitioningsProto.javaDescriptor.getMessageTypes().get(2)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = PartitioningsProto.scalaDescriptor.messages(2)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 2 => __out = edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning(
    batchSize = 0,
    channels = _root_.scala.Seq.empty
  )
  implicit class RoundRobinPartitioningLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning](_l) {
    def batchSize: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.batchSize)((c_, f_) => c_.copy(batchSize = f_))
    def channels: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]] = field(_.channels)((c_, f_) => c_.copy(channels = f_))
  }
  final val BATCHSIZE_FIELD_NUMBER = 1
  final val CHANNELS_FIELD_NUMBER = 2
  def of(
    batchSize: _root_.scala.Int,
    channels: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]
  ): _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning = _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning(
    batchSize,
    channels
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.RoundRobinPartitioning])
}

@SerialVersionUID(0L)
final case class HashBasedShufflePartitioning(
    batchSize: _root_.scala.Int,
    channels: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity],
    hashAttributeNames: _root_.scala.Seq[_root_.scala.Predef.String]
    ) extends scalapb.GeneratedMessage with edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.NonEmpty with scalapb.lenses.Updatable[HashBasedShufflePartitioning] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = batchSize
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(1, __value)
        }
      };
      channels.foreach { __item =>
        val __value = __item
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      hashAttributeNames.foreach { __item =>
        val __value = __item
        __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(3, __value)
      }
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = batchSize
        if (__v != 0) {
          _output__.writeInt32(1, __v)
        }
      };
      channels.foreach { __v =>
        val __m = __v
        _output__.writeTag(2, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      hashAttributeNames.foreach { __v =>
        val __m = __v
        _output__.writeString(3, __m)
      };
    }
    def withBatchSize(__v: _root_.scala.Int): HashBasedShufflePartitioning = copy(batchSize = __v)
    def clearChannels = copy(channels = _root_.scala.Seq.empty)
    def addChannels(__vs: edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity *): HashBasedShufflePartitioning = addAllChannels(__vs)
    def addAllChannels(__vs: Iterable[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]): HashBasedShufflePartitioning = copy(channels = channels ++ __vs)
    def withChannels(__v: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]): HashBasedShufflePartitioning = copy(channels = __v)
    def clearHashAttributeNames = copy(hashAttributeNames = _root_.scala.Seq.empty)
    def addHashAttributeNames(__vs: _root_.scala.Predef.String *): HashBasedShufflePartitioning = addAllHashAttributeNames(__vs)
    def addAllHashAttributeNames(__vs: Iterable[_root_.scala.Predef.String]): HashBasedShufflePartitioning = copy(hashAttributeNames = hashAttributeNames ++ __vs)
    def withHashAttributeNames(__v: _root_.scala.Seq[_root_.scala.Predef.String]): HashBasedShufflePartitioning = copy(hashAttributeNames = __v)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = batchSize
          if (__t != 0) __t else null
        }
        case 2 => channels
        case 3 => hashAttributeNames
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PInt(batchSize)
        case 2 => _root_.scalapb.descriptors.PRepeated(channels.iterator.map(_.toPMessage).toVector)
        case 3 => _root_.scalapb.descriptors.PRepeated(hashAttributeNames.iterator.map(_root_.scalapb.descriptors.PString(_)).toVector)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToSingleLineUnicodeString(this)
    def companion: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning.type = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning
    // @@protoc_insertion_point(GeneratedMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.HashBasedShufflePartitioning])
}

object HashBasedShufflePartitioning extends scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning = {
    var __batchSize: _root_.scala.Int = 0
    val __channels: _root_.scala.collection.immutable.VectorBuilder[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity] = new _root_.scala.collection.immutable.VectorBuilder[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]
    val __hashAttributeNames: _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Predef.String] = new _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Predef.String]
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 8 =>
          __batchSize = _input__.readInt32()
        case 18 =>
          __channels += _root_.scalapb.LiteParser.readMessage[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity](_input__)
        case 26 =>
          __hashAttributeNames += _input__.readStringRequireUtf8()
        case tag => _input__.skipField(tag)
      }
    }
    edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning(
        batchSize = __batchSize,
        channels = __channels.result(),
        hashAttributeNames = __hashAttributeNames.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning(
        batchSize = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        channels = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]]).getOrElse(_root_.scala.Seq.empty),
        hashAttributeNames = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Seq[_root_.scala.Predef.String]]).getOrElse(_root_.scala.Seq.empty)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = PartitioningsProto.javaDescriptor.getMessageTypes().get(3)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = PartitioningsProto.scalaDescriptor.messages(3)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 2 => __out = edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning(
    batchSize = 0,
    channels = _root_.scala.Seq.empty,
    hashAttributeNames = _root_.scala.Seq.empty
  )
  implicit class HashBasedShufflePartitioningLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning](_l) {
    def batchSize: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.batchSize)((c_, f_) => c_.copy(batchSize = f_))
    def channels: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]] = field(_.channels)((c_, f_) => c_.copy(channels = f_))
    def hashAttributeNames: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[_root_.scala.Predef.String]] = field(_.hashAttributeNames)((c_, f_) => c_.copy(hashAttributeNames = f_))
  }
  final val BATCHSIZE_FIELD_NUMBER = 1
  final val CHANNELS_FIELD_NUMBER = 2
  final val HASHATTRIBUTENAMES_FIELD_NUMBER = 3
  def of(
    batchSize: _root_.scala.Int,
    channels: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity],
    hashAttributeNames: _root_.scala.Seq[_root_.scala.Predef.String]
  ): _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning = _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning(
    batchSize,
    channels,
    hashAttributeNames
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.HashBasedShufflePartitioning])
}

@SerialVersionUID(0L)
final case class RangeBasedShufflePartitioning(
    batchSize: _root_.scala.Int,
    channels: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity],
    rangeAttributeNames: _root_.scala.Seq[_root_.scala.Predef.String],
    rangeMin: _root_.scala.Long,
    rangeMax: _root_.scala.Long
    ) extends scalapb.GeneratedMessage with edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.NonEmpty with scalapb.lenses.Updatable[RangeBasedShufflePartitioning] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = batchSize
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(1, __value)
        }
      };
      channels.foreach { __item =>
        val __value = __item
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      rangeAttributeNames.foreach { __item =>
        val __value = __item
        __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(3, __value)
      }
      
      {
        val __value = rangeMin
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(4, __value)
        }
      };
      
      {
        val __value = rangeMax
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(5, __value)
        }
      };
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = batchSize
        if (__v != 0) {
          _output__.writeInt32(1, __v)
        }
      };
      channels.foreach { __v =>
        val __m = __v
        _output__.writeTag(2, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      rangeAttributeNames.foreach { __v =>
        val __m = __v
        _output__.writeString(3, __m)
      };
      {
        val __v = rangeMin
        if (__v != 0L) {
          _output__.writeInt64(4, __v)
        }
      };
      {
        val __v = rangeMax
        if (__v != 0L) {
          _output__.writeInt64(5, __v)
        }
      };
    }
    def withBatchSize(__v: _root_.scala.Int): RangeBasedShufflePartitioning = copy(batchSize = __v)
    def clearChannels = copy(channels = _root_.scala.Seq.empty)
    def addChannels(__vs: edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity *): RangeBasedShufflePartitioning = addAllChannels(__vs)
    def addAllChannels(__vs: Iterable[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]): RangeBasedShufflePartitioning = copy(channels = channels ++ __vs)
    def withChannels(__v: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]): RangeBasedShufflePartitioning = copy(channels = __v)
    def clearRangeAttributeNames = copy(rangeAttributeNames = _root_.scala.Seq.empty)
    def addRangeAttributeNames(__vs: _root_.scala.Predef.String *): RangeBasedShufflePartitioning = addAllRangeAttributeNames(__vs)
    def addAllRangeAttributeNames(__vs: Iterable[_root_.scala.Predef.String]): RangeBasedShufflePartitioning = copy(rangeAttributeNames = rangeAttributeNames ++ __vs)
    def withRangeAttributeNames(__v: _root_.scala.Seq[_root_.scala.Predef.String]): RangeBasedShufflePartitioning = copy(rangeAttributeNames = __v)
    def withRangeMin(__v: _root_.scala.Long): RangeBasedShufflePartitioning = copy(rangeMin = __v)
    def withRangeMax(__v: _root_.scala.Long): RangeBasedShufflePartitioning = copy(rangeMax = __v)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = batchSize
          if (__t != 0) __t else null
        }
        case 2 => channels
        case 3 => rangeAttributeNames
        case 4 => {
          val __t = rangeMin
          if (__t != 0L) __t else null
        }
        case 5 => {
          val __t = rangeMax
          if (__t != 0L) __t else null
        }
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PInt(batchSize)
        case 2 => _root_.scalapb.descriptors.PRepeated(channels.iterator.map(_.toPMessage).toVector)
        case 3 => _root_.scalapb.descriptors.PRepeated(rangeAttributeNames.iterator.map(_root_.scalapb.descriptors.PString(_)).toVector)
        case 4 => _root_.scalapb.descriptors.PLong(rangeMin)
        case 5 => _root_.scalapb.descriptors.PLong(rangeMax)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToSingleLineUnicodeString(this)
    def companion: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning.type = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning
    // @@protoc_insertion_point(GeneratedMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.RangeBasedShufflePartitioning])
}

object RangeBasedShufflePartitioning extends scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning = {
    var __batchSize: _root_.scala.Int = 0
    val __channels: _root_.scala.collection.immutable.VectorBuilder[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity] = new _root_.scala.collection.immutable.VectorBuilder[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]
    val __rangeAttributeNames: _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Predef.String] = new _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Predef.String]
    var __rangeMin: _root_.scala.Long = 0L
    var __rangeMax: _root_.scala.Long = 0L
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 8 =>
          __batchSize = _input__.readInt32()
        case 18 =>
          __channels += _root_.scalapb.LiteParser.readMessage[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity](_input__)
        case 26 =>
          __rangeAttributeNames += _input__.readStringRequireUtf8()
        case 32 =>
          __rangeMin = _input__.readInt64()
        case 40 =>
          __rangeMax = _input__.readInt64()
        case tag => _input__.skipField(tag)
      }
    }
    edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning(
        batchSize = __batchSize,
        channels = __channels.result(),
        rangeAttributeNames = __rangeAttributeNames.result(),
        rangeMin = __rangeMin,
        rangeMax = __rangeMax
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning(
        batchSize = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        channels = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]]).getOrElse(_root_.scala.Seq.empty),
        rangeAttributeNames = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Seq[_root_.scala.Predef.String]]).getOrElse(_root_.scala.Seq.empty),
        rangeMin = __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        rangeMax = __fieldsMap.get(scalaDescriptor.findFieldByNumber(5).get).map(_.as[_root_.scala.Long]).getOrElse(0L)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = PartitioningsProto.javaDescriptor.getMessageTypes().get(4)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = PartitioningsProto.scalaDescriptor.messages(4)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 2 => __out = edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning(
    batchSize = 0,
    channels = _root_.scala.Seq.empty,
    rangeAttributeNames = _root_.scala.Seq.empty,
    rangeMin = 0L,
    rangeMax = 0L
  )
  implicit class RangeBasedShufflePartitioningLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning](_l) {
    def batchSize: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.batchSize)((c_, f_) => c_.copy(batchSize = f_))
    def channels: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]] = field(_.channels)((c_, f_) => c_.copy(channels = f_))
    def rangeAttributeNames: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[_root_.scala.Predef.String]] = field(_.rangeAttributeNames)((c_, f_) => c_.copy(rangeAttributeNames = f_))
    def rangeMin: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.rangeMin)((c_, f_) => c_.copy(rangeMin = f_))
    def rangeMax: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.rangeMax)((c_, f_) => c_.copy(rangeMax = f_))
  }
  final val BATCHSIZE_FIELD_NUMBER = 1
  final val CHANNELS_FIELD_NUMBER = 2
  final val RANGEATTRIBUTENAMES_FIELD_NUMBER = 3
  final val RANGEMIN_FIELD_NUMBER = 4
  final val RANGEMAX_FIELD_NUMBER = 5
  def of(
    batchSize: _root_.scala.Int,
    channels: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity],
    rangeAttributeNames: _root_.scala.Seq[_root_.scala.Predef.String],
    rangeMin: _root_.scala.Long,
    rangeMax: _root_.scala.Long
  ): _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning = _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning(
    batchSize,
    channels,
    rangeAttributeNames,
    rangeMin,
    rangeMax
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.RangeBasedShufflePartitioning])
}

@SerialVersionUID(0L)
final case class BroadcastPartitioning(
    batchSize: _root_.scala.Int,
    channels: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]
    ) extends scalapb.GeneratedMessage with edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.NonEmpty with scalapb.lenses.Updatable[BroadcastPartitioning] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = batchSize
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(1, __value)
        }
      };
      channels.foreach { __item =>
        val __value = __item
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = batchSize
        if (__v != 0) {
          _output__.writeInt32(1, __v)
        }
      };
      channels.foreach { __v =>
        val __m = __v
        _output__.writeTag(2, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
    }
    def withBatchSize(__v: _root_.scala.Int): BroadcastPartitioning = copy(batchSize = __v)
    def clearChannels = copy(channels = _root_.scala.Seq.empty)
    def addChannels(__vs: edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity *): BroadcastPartitioning = addAllChannels(__vs)
    def addAllChannels(__vs: Iterable[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]): BroadcastPartitioning = copy(channels = channels ++ __vs)
    def withChannels(__v: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]): BroadcastPartitioning = copy(channels = __v)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = batchSize
          if (__t != 0) __t else null
        }
        case 2 => channels
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PInt(batchSize)
        case 2 => _root_.scalapb.descriptors.PRepeated(channels.iterator.map(_.toPMessage).toVector)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToSingleLineUnicodeString(this)
    def companion: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning.type = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning
    // @@protoc_insertion_point(GeneratedMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.BroadcastPartitioning])
}

object BroadcastPartitioning extends scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning = {
    var __batchSize: _root_.scala.Int = 0
    val __channels: _root_.scala.collection.immutable.VectorBuilder[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity] = new _root_.scala.collection.immutable.VectorBuilder[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 8 =>
          __batchSize = _input__.readInt32()
        case 18 =>
          __channels += _root_.scalapb.LiteParser.readMessage[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity](_input__)
        case tag => _input__.skipField(tag)
      }
    }
    edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning(
        batchSize = __batchSize,
        channels = __channels.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning(
        batchSize = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        channels = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]]).getOrElse(_root_.scala.Seq.empty)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = PartitioningsProto.javaDescriptor.getMessageTypes().get(5)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = PartitioningsProto.scalaDescriptor.messages(5)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 2 => __out = edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning(
    batchSize = 0,
    channels = _root_.scala.Seq.empty
  )
  implicit class BroadcastPartitioningLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning](_l) {
    def batchSize: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.batchSize)((c_, f_) => c_.copy(batchSize = f_))
    def channels: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]] = field(_.channels)((c_, f_) => c_.copy(channels = f_))
  }
  final val BATCHSIZE_FIELD_NUMBER = 1
  final val CHANNELS_FIELD_NUMBER = 2
  def of(
    batchSize: _root_.scala.Int,
    channels: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ChannelIdentity]
  ): _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning = _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.BroadcastPartitioning(
    batchSize,
    channels
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.BroadcastPartitioning])
}
